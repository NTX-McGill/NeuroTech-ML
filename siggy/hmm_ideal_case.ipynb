{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HMM for the ideal case, i.e. where are given the mapped finger with probability 1 for each letter in the input string, according to the touch type mapping defined in `finger_letter_mapping`. \n",
    "Input dataset: `nltk 'abc'` sentences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Home\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "from keras.utils import to_categorical\n",
    "from nltk.tag import hmm\n",
    "from nltk.probability import LaplaceProbDist\n",
    "import random\n",
    "\n",
    "from finger_letter_mapping import letter_finger, finger_letter\n",
    "from test_generation import * # importantly, text_to_label (for generating labels) and text_to_realistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package abc to\n",
      "[nltk_data]     C:\\Users\\Home\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package abc is already up-to-date!\n",
      "[nltk_data] Downloading package nps_chat to\n",
      "[nltk_data]     C:\\Users\\Home\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package nps_chat is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('abc')\n",
    "nltk.download('nps_chat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.corpus.abc.sents()[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smartcheck.smartcheck import Smartcheck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordsplit_to_sent(data) : \n",
    "    ''' Input array of sentences where sentence = array of words. \n",
    "    Output array of sentences where sentence = string.\n",
    "    '''\n",
    "    return [' '.join(sent)[:-2].lower() for sent in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get 9000 sentences each as array split by word, for training \n",
    "sentences_wordsplit = nltk.corpus.abc.sents()[:9000]   \n",
    "# get 1000 sentences for testing \n",
    "tester_wordsplit = nltk.corpus.abc.sents()[10000:11000]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn each sentence from a word array into a sentence string\n",
    "train_sentences = wordsplit_to_sent(sentences_wordsplit)  \n",
    "test_sentences = wordsplit_to_sent(tester_wordsplit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pm denies knowledge of awb kickbacks the prime minister has denied he knew awb was paying kickbacks to iraq despite writing to the wheat exporter asking to be kept fully informed on iraq wheat sales', 'letters from john howard and deputy prime minister mark vaile to awb have been released by the cole inquiry into the oil for food program']\n",
      "['compo for murray valley irrigators ruled out the new south wales government has ruled out compensation for murray valley irrigators affected by water cut backs', 'high security allocations and carry over water in the murray valley have been cut by 20 per cent because of record low inflows']\n"
     ]
    }
   ],
   "source": [
    "print(train_sentences[:2])\n",
    "print(test_sentences[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename \n",
    "training = train_sentences\n",
    "testing = test_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f1 = open('training.txt', 'r')\n",
    "# f2 = open('testing.txt', 'r')\n",
    "# training = f1.read().lower().splitlines()\n",
    "# testing = f2.read().lower().splitlines()\n",
    "# f1.close()\n",
    "# f2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Letter space (hidden states):\n",
      "  dict_keys(['q', 'a', 'z', 'w', 's', 'x', 'e', 'd', 'c', 'r', 'f', 'v', 't', 'g', 'b', 'p', 'o', 'l', 'i', 'k', 'u', 'j', 'm', 'y', 'h', 'n', ' '])\n",
      "Finger space (observed states): \n",
      " dict_keys([10, 9, 8, 7, 1, 5, 4, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "print('Letter space (hidden states):\\n ', letter_finger.keys())\n",
    "print('Finger space (observed states): \\n', finger_letter.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pm denies knowledge of awb kickbacks the prime minister has denied he knew awb was paying kickbacks to iraq despite writing to the wheat exporter asking to be kept fully informed on iraq wheat sales\n"
     ]
    }
   ],
   "source": [
    "print(training[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2  3  1  7  2  3  9  1  3  9  1 10  1  7  8  9  7]\n",
      "['h' 'i' ' ' 't' 'h' 'i' 's' ' ' 'i' 's' ' ' 'a' ' ' 't' 'e' 's' 't']\n"
     ]
    }
   ],
   "source": [
    "print(text_to_finger('hi, this is a TEST'))\n",
    "print(text_to_label('hi, this is a TEST'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reality check: 9000 9000\n",
      "198 198\n"
     ]
    }
   ],
   "source": [
    "# ideal mapping, no repeats or probabilities\n",
    "mapped_training = text_to_finger(training)\n",
    "mapped_testing = text_to_finger(testing)\n",
    "labels_training = text_to_label(training)\n",
    "labels_testing = text_to_label(testing)\n",
    "\n",
    "# list(map(lambda c: letter_finger[c] if c in letter_finger.keys() else None, sample_text.lower()))\n",
    "print('reality check:', mapped_training.size, len(labels_training))\n",
    "print(mapped_training[0].size, labels_training[0].size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no repeats, one-hot encoding\n",
    "onehot_training = finger_to_onehot(mapped_training)\n",
    "onehot_testing = finger_to_onehot(mapped_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = text_to_realistic(training[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# important one! repeats + probability vector\n",
    "siggy_generation = text_to_realistic(training)  # 18 secs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to turn one hot back to label: np.argmax(mapped_one_hot[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "turn finger mapping back to text using HMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = hmm.HiddenMarkovModelTrainer(states = letter_finger.keys(), symbols = finger_letter.keys())\n",
    "# symbols: observations ; states: hidden states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est = LaplaceProbDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_seq(finger, labels): \n",
    "    out = []\n",
    "    for i in range(len(finger)): \n",
    "        out.append([(ss, target) for ss, target in zip(finger[i], labels[i])])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = make_seq(mapped_training, labels_training)\n",
    "test_seq = make_seq(mapped_testing, labels_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagger = trainer.train_supervised(seq, estimator=est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy over 133408 tokens: 78.84\n"
     ]
    }
   ],
   "source": [
    "tagger.test(test_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def letters_to_sents(tuple_list):  # turn [[(finger, letter), (.,.)], [...]] to list of sentences \n",
    "    return [''.join([y for (x,y) in entry]) for entry in tuple_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_true_output = letters_to_sents(test_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = [[x for (x,y) in entry] for entry in test_seq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_out = [tagger.tag(sent) for sent in test_input]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_out_sents = letters_to_sents(test_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Home\\Desktop\\Projects\\NeuroTech2020\\NeuroTech-ML\\siggy\\smartcheck\n"
     ]
    }
   ],
   "source": [
    "% cd smartcheck \n",
    "% pwd\n",
    "checker = Smartcheck()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sentence'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checker.correction('sentance', 'the')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mith wedutith allleatious and catry orer warer in the ungran tallen hare been cut th  per ceng becanse or becore lls intolss', 'the hathral besongees minister  ian haccomale  wans the warer will be pake tack in ththre  wo there is mo hede tor compensation', 'he wans more heasures to ncop the tathing counmmith will be anmounded in the hest torthitht', 'ctontht cominares hatiomal ticod cans hes and inmorative wans or coping with the ctontht are the most populat eshitits at this heat  s hatiomal ticod cans  engrenton under wan at orange in cengral  westery hes wonth wales', 'anazinton  the long  thuning ctontht has mor caupende the spitits or thowe atrending the hatiomal ticod cans at torenore']\n",
      "['high security allocations and carry over water in the murray valley have been cut by  per cent because of record low inflows', 'the natural resources minister  ian macdonald  says the water will be paid back in future  so there is no need for compensation', 'he says more measures to help the farming community will be announced in the next fortnight', 'drought dominates national field days new and innovative ways of coping with the drought are the most popular exhibits at this year  s national field days  currently under way at orange in central  western new south wales', 'amazingly  the long  running drought has not dampened the spirits of those attending the national field days at borenore']\n"
     ]
    }
   ],
   "source": [
    "print(test_out_sents[1:6])\n",
    "print(test_true_output[1:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "spellchecked = [checker.correct_sentence(sentence) for sentence in test_out_sents[:100]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from spell import correction\n",
    "# letters_to_sents([tagger.tag([letter_finger[c] for c in 'hello this is a testing open computer'])])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percent_correct(out_list, true_list): \n",
    "    total_count = 0\n",
    "    for i in range(len(out_list)): \n",
    "        count = sum(1 for a, b in zip(out_list[i].split(), true_list[i].split()) if a == b)\n",
    "        total_count += count\n",
    "    total = sum(len(a.split()) for a in true_list)\n",
    "    return total_count / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54.091300602928506"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percent_correct(spellchecked, test_true_output[:100])*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
