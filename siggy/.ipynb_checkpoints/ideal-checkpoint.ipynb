{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Home\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "from keras.utils import to_categorical\n",
    "from nltk.tag import hmm\n",
    "from nltk.probability import LaplaceProbDist\n",
    "import random\n",
    "\n",
    "from finger_letter_mapping import letter_finger, finger_letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package abc to\n",
      "[nltk_data]     C:\\Users\\Home\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package abc is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Home\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('abc')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordsplit_to_sent(data) : \n",
    "    return [' '.join(sent)[:-2].lower() for sent in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_wordsplit = nltk.corpus.abc.sents()[:9000]\n",
    "tester_wordsplit = nltk.corpus.abc.sents()[10000:11000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences = wordsplit_to_sent(sentences_wordsplit)\n",
    "test_sentences = wordsplit_to_sent(tester_wordsplit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pm denies knowledge of awb kickbacks the prime minister has denied he knew awb was paying kickbacks to iraq despite writing to the wheat exporter asking to be kept fully informed on iraq wheat sales',\n",
       " 'letters from john howard and deputy prime minister mark vaile to awb have been released by the cole inquiry into the oil for food program']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['compo for murray valley irrigators ruled out the new south wales government has ruled out compensation for murray valley irrigators affected by water cut backs',\n",
       " 'high security allocations and carry over water in the murray valley have been cut by 20 per cent because of record low inflows']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentences[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = train_sentences\n",
    "testing = test_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f1 = open('training.txt', 'r')\n",
    "# f2 = open('testing.txt', 'r')\n",
    "# training = f1.read().lower().splitlines()\n",
    "# testing = f2.read().lower().splitlines()\n",
    "# f1.close()\n",
    "# f2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Letter space (hidden states):\n",
      "  dict_keys(['q', 'a', 'z', 'w', 's', 'x', 'e', 'd', 'c', 'r', 'f', 'v', 't', 'g', 'b', 'p', 'o', 'l', 'i', 'k', 'u', 'j', 'm', 'y', 'h', 'n', ' '])\n",
      "Finger space (observed states): \n",
      " dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8])\n"
     ]
    }
   ],
   "source": [
    "print('Letter space (hidden states):\\n ', letter_finger.keys())\n",
    "print('Finger space (observed states): \\n', finger_letter.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pm denies knowledge of awb kickbacks the prime minister has denied he knew awb was paying kickbacks to iraq despite writing to the wheat exporter asking to be kept fully informed on iraq wheat sales\n"
     ]
    }
   ],
   "source": [
    "print(training[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_finger(data): \n",
    "    output = [] \n",
    "    for row in data:\n",
    "        output.append(np.array([letter_finger[c] for c in row.lower() if c in letter_finger.keys()]))\n",
    "    return np.array(output)\n",
    "def text_to_label(data): \n",
    "    output = []\n",
    "    for row in data: \n",
    "        output.append(np.array(list(filter(lambda c: c in letter_finger.keys(), row))))\n",
    "    return np.array(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reality check: 9000 9000\n",
      "198 198\n"
     ]
    }
   ],
   "source": [
    "mapped_training = text_to_finger(training)\n",
    "mapped_testing = text_to_finger(testing)\n",
    "labels_training = text_to_label(training)\n",
    "labels_testing = text_to_label(testing)\n",
    "\n",
    "# list(map(lambda c: letter_finger[c] if c in letter_finger.keys() else None, sample_text.lower()))\n",
    "print('reality check:', mapped_training.size, len(labels_training))\n",
    "print(mapped_training[0].size, labels_training[0].size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finger_to_onehot(data): \n",
    "    return np.array([to_categorical(row) for row in data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_training = finger_to_onehot(mapped_training)\n",
    "onehot_testing = finger_to_onehot(mapped_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: add noise to one hot encoding \n",
    "\n",
    "# to turn one hot back to label: np.argmax(mapped_one_hot[0])\n",
    "# mapped_noise = [letter + NOISE for letter in mapped_one_hot]\n",
    "# for letter in mapped_one_hot: \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "turn finger mapping back to text using HMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = hmm.HiddenMarkovModelTrainer(states = letter_finger.keys(), symbols = finger_letter.keys())\n",
    "# symbols: observations ; states: hidden states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "est = LaplaceProbDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_seq(finger, labels): \n",
    "    out = []\n",
    "    for i in range(len(finger)): \n",
    "        out.append([(ss, target) for ss, target in zip(finger[i], labels[i])])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = make_seq(mapped_training, labels_training)\n",
    "test_seq = make_seq(mapped_testing, labels_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagger = trainer.train_supervised(seq, estimator=est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy over 133408 tokens: 78.84\n"
     ]
    }
   ],
   "source": [
    "tagger.test(test_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def letters_to_sents(tuple_list):  # turn [[(finger, letter), (.,.)], [...]] to list of sentences \n",
    "    return [''.join([y for (x,y) in entry]) for entry in tuple_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_true_output = letters_to_sents(test_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = [[x for (x,y) in entry] for entry in test_seq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_out = [tagger.tag(sent) for sent in test_input]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_out_sents = letters_to_sents(test_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spell import correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fig1, ax1 = plt.subplots()\n",
    "# ax1.pie([78.39, 100-78.39], explode=[0.1,0], autopct='%1.1f%%', shadow=True)\n",
    "# ax1.axis('equal')\n",
    "# plt.title(\"HMM Accuracy\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'helll this is a besting open compurer'"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "letters_to_sents([tagger.tag([letter_finger[c] for c in 'hello this is a testing open computer'])])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
